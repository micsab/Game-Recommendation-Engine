{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-31T06:10:44.618663Z",
     "start_time": "2018-12-31T06:10:43.733663Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup, SoupStrainer\n",
    "import requests\n",
    "import lxml\n",
    "from requests import exceptions\n",
    "import pandas as pd\n",
    "import sys\n",
    "from io import StringIO\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T01:00:25.357467Z",
     "start_time": "2018-12-31T21:23:31.323185Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-bd10431ce809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m                                      \u001b[1;34m'number_of_review'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnum_reviews\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                                      \u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrating_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                                      'release_date': releases})\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0msteam_scrape_the_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_links\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe_rest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   7354\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7356\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7358\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7402\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7404\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df_links = pd.read_csv('products_v2.csv', delimiter=\"\\t\")\n",
    "\n",
    "descriptions = []\n",
    "num_reviews = []\n",
    "rating_values = []\n",
    "releases = []\n",
    "\n",
    "cookies = {'birthtime': '568022401'}\n",
    "\n",
    "for link in df_links.iterrows():\n",
    "    try:\n",
    "        url = link[1]['steam_url']\n",
    "        r = requests.get(url, cookies=cookies)\n",
    "        page_soup = soup(r.content, 'lxml')\n",
    "        description = page_soup.find('div', {'class': 'game_description_snippet'}).text.replace('\\t','').replace('\\r','').replace('\\n', '')\n",
    "        descriptions.append(description)\n",
    "        #print(description)\n",
    "\n",
    "        num_review = int(page_soup.find('meta', {'itemprop':'reviewCount'})['content'])\n",
    "        num_reviews.append(num_review)\n",
    "\n",
    "        rating_value = float(page_soup.find('meta', {'itemprop':'ratingValue'})['content'])\n",
    "        rating_values.append(rating_value)\n",
    "\n",
    "        release = page_soup.find('div', {'class': 'date'}).text\n",
    "        releases.append(release)\n",
    "    except:\n",
    "        description = 'no description'\n",
    "        descriptions.append(description)\n",
    "        \n",
    "        num_review = 'no reviews'\n",
    "        num_reviews.append(num_review)\n",
    "\n",
    "        rating_value = 'no ratings'\n",
    "        rating_values.append(rating_value)\n",
    "\n",
    "        release = 'no release date'\n",
    "        releases.append(release)\n",
    "        \n",
    "    \n",
    "the_rest = pd.DataFrame({'description': descriptions,\n",
    "                                     'number_of_review': num_reviews,\n",
    "                                     'score': rating_values,\n",
    "                                     'release_date': releases})\n",
    "\n",
    "steam_scrape_the_rest = pd.concat([df_links, the_rest], axis=1, sort=False)\n",
    "steam_scrape_the_rest.to_csv('the_rest_of_the_fields.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T05:29:28.960359Z",
     "start_time": "2019-01-01T01:37:16.556822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_links = pd.read_csv('products_v2.csv', delimiter=\"\\t\")\n",
    "\n",
    "descriptions = []\n",
    "num_reviews = []\n",
    "rating_values = []\n",
    "releases = []\n",
    "\n",
    "cookies = {'birthtime': '568022401'}\n",
    "\n",
    "for link in df_links.iterrows():\n",
    "    try:\n",
    "        url = link[1]['steam_url']\n",
    "        r = requests.get(url, cookies=cookies)\n",
    "        page_soup = soup(r.content, 'lxml')\n",
    "        description = page_soup.find('div', {'class': 'game_description_snippet'}).text.replace('\\t','').replace('\\r','').replace('\\n', '')\n",
    "        num_review = int(page_soup.find('meta', {'itemprop':'reviewCount'})['content'])\n",
    "        rating_value = float(page_soup.find('meta', {'itemprop':'ratingValue'})['content'])\n",
    "        release = page_soup.find('div', {'class': 'date'}).text\n",
    "        \n",
    "        descriptions.append(description)\n",
    "        num_reviews.append(num_review)\n",
    "        rating_values.append(rating_value)\n",
    "        releases.append(release)\n",
    "    except:\n",
    "        description = 'no description'\n",
    "        num_review = 'no reviews'\n",
    "        rating_value = 'no ratings'\n",
    "        release = 'no release date'\n",
    "        \n",
    "        descriptions.append(description)\n",
    "        num_reviews.append(num_review)\n",
    "        rating_values.append(rating_value)\n",
    "        releases.append(release)\n",
    "        \n",
    "    \n",
    "the_rest = pd.DataFrame({'description': descriptions,\n",
    "                                     'number_of_review': num_reviews,\n",
    "                                     'score': rating_values,\n",
    "                                     'release_date': releases})\n",
    "\n",
    "steam_scrape_the_rest = pd.concat([df_links, the_rest], axis=1, sort=False)\n",
    "steam_scrape_the_rest.to_csv('the_rest_of_the_fields.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-31T21:16:07.009003Z",
     "start_time": "2018-12-31T21:15:30.906211Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in descriptions:\n",
    "    count = descriptions.count(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T09:19:04.897715Z",
     "start_time": "2019-01-01T09:19:04.894712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29550\n",
      "29550\n",
      "29550\n",
      "29550\n"
     ]
    }
   ],
   "source": [
    "print(len(descriptions))\n",
    "print(len(num_reviews))\n",
    "print(len(rating_values))\n",
    "print(len(releases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-31T07:25:59.022454Z",
     "start_time": "2018-12-31T07:25:58.753592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://store.steampowered.com/app/578650/The_Outer_Worlds/?snr=1_7_7_230_150_1174'\n",
    "r = requests.get(url, cookies=cookies)\n",
    "page_soup = soup(r.content, 'lxml')\n",
    "page_soup.find('div', {'class': 'date'}).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
